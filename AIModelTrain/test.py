import torch
import torch.nn as nn
import jieba
import pickle
from model_def import ChineseVocab, ChineseClassifier

# åŠ è½½è¯è¡¨å’Œæ¨¡å‹
def load_resources():
    # 1. åŠ è½½è¯è¡¨
    with open('vocab.pkl', 'rb') as f:
        vocab = pickle.load(f)
    
    # 2. åˆå§‹åŒ–æ¨¡å‹å¹¶åŠ è½½æƒé‡
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = ChineseClassifier(len(vocab)).to(device)
    model.load_state_dict(torch.load('chinese_model.pth', map_location=device))
    model.eval() # å¼€å¯é¢„æµ‹æ¨¡å¼
    
    return vocab, model, device

def predict(text, vocab, model, device):
    with torch.no_grad():
        # ä½¿ç”¨åŠ è½½çš„è¯è¡¨è¿›è¡Œç¼–ç 
        tokens = list(jieba.cut(text))
        ids = [vocab.stoi.get(word, 0) for word in tokens]
        
        ids_tensor = torch.tensor(ids, dtype=torch.int64).to(device)
        offsets = torch.tensor([0]).to(device)
        
        output = model(ids_tensor, offsets)
        prob = torch.sigmoid(output).item()
        return "æ­£é¢ ğŸ˜„" if prob > 0.5 else "è´Ÿé¢ ğŸ˜¡", prob

if __name__ == "__main__":
    vocab, model, device = load_resources()
    print("æ¨¡å‹å’Œè¯è¡¨åŠ è½½å®Œæ¯•ï¼")
    
    while True:
        user_input = input("\nè¯·è¾“å…¥è¦æµ‹è¯•çš„å¥å­ (è¾“å…¥ q é€€å‡º): ")
        if user_input.lower() == 'q':
            break
        
        res, prob = predict(user_input, vocab, model, device)
        print(f"é¢„æµ‹ç»“æœ: {res} (å¯é åº¦: {prob:.4f})")

